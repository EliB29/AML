[["index.html", "Applied Machine Learning Chapter 1 Introduction 1.1 Dataset 1.2 The models 1.3 Use of Generative AI", " Applied Machine Learning Sheptim Veseli &amp; Eliana Perea Barreto 2024-06-06 Chapter 1 Introduction In the contemporary landscape of Applied Machine Learning, predictive modeling has emerged as a crucial field of study to derive insights from data. This field encompasses a variety of methods, each showcasing distinct capabilities worthy of exploration. This project aims to comprehensively understand six machine learning methods, focusing on their application, structure, and outcomes, by covering the following key aspects. Firstly, an overview to introduce the fundamental principles of the model. Following, an in-depth examination of the algorithmic framework to explore the model’s architecture and computational mechanisms. Subsequently, a detailed description of the model’s training and predicting process to elucidate how the model acquires knowledge and makes predictions. Finally, an assessment of the strengths and limitations of the model to evaluate its practical utility, considering factors like interpretability, scalability and computational complexity. 1.1 Dataset The dataset comprises an array of 19 predictors that withhold historical information regarding flight operations for all aircrafts departing from New York City airports throughout 2013. This table is easily accessible through the implementation of the following code: library(nycflights13) data_flight &lt;- flights As you can see in the code, this dataset is sourced from the nycflights13 library in R, and despite containing only 19 predictors, it encompasses a total of 336,776 entries, which exceeds the criteria for a “moderate” dataset. To meet the project’s criteria of working with a dataset within a range of 10^3 to 10^5 rows, and also to simplify the analysis of the data, a method of random sampling is used to shrink the table to 5000 entries. Click on Code Preview to learn how this operation is coded. Code Preview # Set random seed to ensure reproducibility. set.seed(123) # Randomly select 5000 row indices and use them to subset original data. selected_indices &lt;- sample(1:nrow(data_flight), 5000, replace = FALSE) data_flight &lt;- data_flight[selected_indices, ] The table contains discrete categorical and numerical variables associated to predictors like year, month, day, carrier, origin, destination, and tail number. Additionally, continuous numerical attributes such as hour, minute, departure time, arrival time, departure delay, arrival delay, air time, and distance are included. Likewise, among the categorical variables, some are ordinal, like the month, while others are nominal, such as carrier, origin, destination, and tail number. Below, you’ll find a detailed depiction of the table layout and the column names: year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier flight tailnum origin dest air_time distance hour minute time_hour 2013 1 1 517 515 2 830 819 11 UA 1545 N14228 EWR IAH 227 1400 5 15 2013-01-01 05:00:00 2013 1 1 533 529 4 850 830 20 UA 1714 N24211 LGA IAH 227 1416 5 29 2013-01-01 05:00:00 2013 1 1 542 540 2 923 850 33 AA 1141 N619AA JFK MIA 160 1089 5 40 2013-01-01 05:00:00 2013 1 1 544 545 -1 1004 1022 -18 B6 725 N804JB JFK BQN 183 1576 5 45 2013-01-01 05:00:00 Utilizing this dataset, the project aims to explore the predictive potential of 6 selected machine learning methods, to forecast the relation between flight arrival delay time and airline name, where carrier (airline name) serves as the primary independent variable, impacting the arr_delay (arrival delay time) as the dependent variable. 1.2 The models Concluding this introduction, here is the list of the selected models to be studied: A simple Linear Model A generalized Linear Model with family set to Poisson A generalized Linear Model with family set to Binomial A Support Vector Machine A generalized Additive Model A neural Network 1.3 Use of Generative AI Generative AI proved particularly effective in providing quick and intuitive explanations of complex concepts, such as the natural logic of odds, and in assisting with debugging R code. However, it had limitations, especially in handling intricate statistical nuances and ensuring the appropriateness of advanced methods for our specific dataset. Some debugging suggestions included irrelevant steps, necessitating careful double-checking. Personalized suggestions tailored to the specific conditions of our model were also challenging, as the AI generally offers broad insights that require us to connect them to our particular case. Despite these limitations, Generative AI was especially useful for creating the README file, providing a structured format that ensured the document was correctly written and all necessary sections were included. "],["simple-linear-model.html", "Chapter 2 Simple Linear Model 2.1 Introduction 2.2 Data Preparation 2.3 Descriptive Statistics 2.4 Linear Regression Analysis 2.5 Diagnostic Plots", " Chapter 2 Simple Linear Model By Sheptim Veseli 2.1 Introduction This analysis investigates the impact of airline carriers on flight arrival delays using the nycflights13 dataset. The dataset contains flight details for all aircraft departing from New York City airports throughout 2013. The objective is to explore the predictive potential of a simple linear regression model, where the arrival delay (arr_delay) is the dependent variable and the carrier (airline name) is the primary independent variable. 2.2 Data Preparation The original dataset comprises 336,776 entries across 19 variables. To meet the project’s criteria of working with a dataset within a range of 10^3 to 10^5 rows, a random sample of 5000 entries was selected. Additionally, rows with missing values in key variables (dep_time, arr_time, arr_delay, tailnum, air_time) were removed, resulting in a cleaned dataset of 2052 rows. Code Preview # Set random seed to ensure reproducibility set.seed(123) # Randomly select 5000 row indices and use them to subset original data selected_indices &lt;- sample(1:nrow(flights), 5000, replace = FALSE) flights_subset &lt;- flights[selected_indices, ] # Remove rows with missing values in key variables flights_subset &lt;- flights_subset[complete.cases(flights_subset$dep_time, flights_subset$arr_time, flights_subset$arr_delay, flights_subset$tailnum, flights_subset$air_time), ] # Remove negative values from arrival delay time (arr_delay) flights_subset &lt;- flights_subset[flights_subset$arr_delay &gt;= 0, ] # Apply logarithmic transformation to arrival delay time (arr_delay) flights_subset$log_arr_delay &lt;- log(flights_subset$arr_delay + 1) 2.3 Descriptive Statistics Descriptive statistics provide a summary of the data’s main characteristics, offering insight into the central tendency, dispersion, and distribution of the dataset. For this analysis, we focus on two key aspects: arrival delays and the distribution of flights among different carriers. 2.3.1 Arrival Delay Statistics The arrival delay data reveals insightful characteristics of flight punctuality. ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00 7.00 19.00 37.06 46.00 681.00 The minimum recorded delay is 0 minutes, indicating that some flights arrived precisely on schedule or even earlier. The first quartile (25th percentile) value is 7 minutes, suggesting that 25% of the flights experienced delays of 7 minutes or less. This relatively low quartile value reflects a significant proportion of flights with minimal delays. The median delay, which represents the 50th percentile, is 19 minutes. This median value implies that half of the flights were delayed by 19 minutes or less, indicating a moderate level of punctuality. However, the mean delay is approximately 37.06 minutes, which is notably higher than the median. This discrepancy between the mean and median suggests the presence of extreme delays that skew the average upward. The third quartile (75th percentile) value is 46 minutes, showing that 75% of the flights were delayed by up to 46 minutes. The maximum recorded delay in the dataset is an alarming 681 minutes, illustrating the significant variability and the potential for exceptionally long delays. 2.3.2 Carrier Statistics Among the carriers, the dataset reveals that B6, EV, and UA are the most frequent, with 344, 376, and 332 flights, respectively. These carriers represent the bulk of the dataset, suggesting they have a substantial operational presence in the New York City area. The presence of a smaller number of flights for carriers like AS and OO, with only 2 and 1 flights respectively, highlights a skewed distribution towards certain airlines. This skewness might reflect the market dominance or higher frequency of operations by these carriers in the specified region and time period. ## ## 9E AA AS B6 DL EV F9 FL MQ OO UA US VX WN YV ## 102 183 2 344 262 376 5 29 188 1 332 115 30 82 1 2.4 Linear Regression Analysis To elucidate the relationship between airline carriers and flight arrival delays, a simple linear regression model was constructed using the logarithm of the arrival delay (log_arr_delay) as the dependent variable and the carrier as the independent variable. The choice to logarithmize the arrival delay variable was motivated by its right-skewed distribution. The logarithmic transformation normalizes this distribution, enhancing the linearity assumption and the overall interpretability of the regression results. The regression model was formulated as follows: \\[ log (\\text{arr_delay}) = β_0 + β_1 ⋅ carrierAA + β_2 ⋅ carrierAS + β_3 ⋅ carrierB6 +⋯ + β_14 ⋅ carrier YV \\] where 0 is the intercept, and  are the coefficients for each carrier compared to the baseline carrier. lm_model_log &lt;- lm(log_arr_delay ~ carrier, data = flights_subset) Summary Preview summary(lm_model_log) ## ## Call: ## lm(formula = log_arr_delay ~ carrier, data = flights_subset) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.2948 -0.8174 0.0375 0.9026 3.7391 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.2948 0.1263 26.093 &lt; 2e-16 *** ## carrierAA -0.5597 0.1576 -3.552 0.000391 *** ## carrierAS -1.3003 0.9106 -1.428 0.153443 ## carrierB6 -0.3235 0.1438 -2.250 0.024573 * ## carrierDL -0.5089 0.1488 -3.419 0.000641 *** ## carrierEV -0.2364 0.1424 -1.661 0.096950 . ## carrierF9 -1.2100 0.5841 -2.071 0.038449 * ## carrierFL -0.5775 0.2684 -2.152 0.031537 * ## carrierMQ -0.2121 0.1568 -1.353 0.176348 ## carrierOO 1.7678 1.2815 1.379 0.167911 ## carrierUA -0.4550 0.1444 -3.152 0.001647 ** ## carrierUS -0.6056 0.1735 -3.491 0.000491 *** ## carrierVX -0.5733 0.2649 -2.165 0.030538 * ## carrierWN -0.4198 0.1892 -2.219 0.026581 * ## carrierYV -0.8099 1.2815 -0.632 0.527480 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.275 on 2037 degrees of freedom ## Multiple R-squared: 0.01754, Adjusted R-squared: 0.01079 ## F-statistic: 2.598 on 14 and 2037 DF, p-value: 0.0009886 2.4.1 Model Summary Residuals: These ranged from -3.2948 to 3.7391, indicating the spread of the differences between observed and predicted log-transformed arrival delays. R-squared: The value was 0.01754, signifying that approximately 1.75% of the variability in the log-transformed arrival delays could be explained by the airline carrier variable alone. Adjusted R-squared: The value was slightly lower at 0.01079, adjusting for the number of predictors. F-statistic: The value was 2.598 with a p-value of 0.0009886, indicating that the overall model was statistically significant. 2.4.2 Significant Carriers The regression coefficients for the carriers were examined to determine their impact on arrival delays. The coefficients and their interpretations are as follows: American Airlines (AA): ^AA=−0.5597, &lt;0.001 β^​AA=−0.5597,p&lt;0.001 This indicates that, on average, American Airlines flights had lower log-transformed arrival delays compared to the baseline carrier. JetBlue (B6): ^B6=−0.3235, &lt;0.05 β^​B6=−0.3235,p&lt;0.05 Suggests a reduction in arrival delays for JetBlue flights. Delta Airlines (DL): ^DL=−0.5089, &lt;0.001 β^DL=−0.5089,p&lt;0.001 Indicates a significant reduction in delays for Delta Airlines. These significant negative coefficients denote that these carriers generally have shorter arrival delays compared to the baseline carrier. The significance of these coefficients was determined by their p-values being less than 0.05, indicating strong evidence against the null hypothesis of no effect. The y-intercept (0) represents the expected value of the log-transformed arrival delay when all other predictors are zero. For the carriers with significant negative coefficients, the interpretation is that these airlines are associated with shorter arrival delays compared to the baseline carrier. The low R-squared value (0.01754) suggests that the carrier variable alone does not explain much of the variability in arrival delays. This indicates that other factors, not included in this simple model, likely play a significant role in influencing arrival delays. These factors could include weather conditions, airport congestion, and specific aircraft issues. 2.5 Diagnostic Plots 2.5.1 Interpretation and Conclusion The linear regression model indicates that certain carriers significantly impact flight arrival delays. Specifically, carriers such as American Airlines, Delta Airlines, and United Airlines, among others, are associated with shorter arrival delays compared to the baseline carrier. However, the low R-squared value highlights that much of the variability in arrival delays remains unexplained by the carrier variable alone, suggesting the presence of other influential factors not included in this model. The diagnostic plots generally confirm the assumptions of the regression model but also point to the presence of potential outliers and influential points that may affect the model’s accuracy. "],["poisson-linear-regression.html", "Chapter 3 Poisson Linear Regression 3.1 Overview 3.2 Algorithmic Framework 3.3 Training &amp; Predicting Process 3.4 Strengths &amp; Limitations", " Chapter 3 Poisson Linear Regression By Eliana Perea Barreto 3.1 Overview Poisson regression stands as a powerful method suited for the analysis of count data, focusing on events expressed as whole numbers. Unlike linear regression, which handles continuous data, Poisson regression suits situations reflecting a Poisson distribution, where the dependent variable (y) represent counts within fixed temporal or spatial boundaries. 3.2 Algorithmic Framework 3.2.1 Data Nature In contrast to continuous variables, Poisson Distribution data points are restricted to non-negative integers, where (y) can only assume values of zero or greater. Illustratively, let’s take a practical look to the implementation of this idea by analyzing the response variable (y) arr_delay from our study case which, as previously mentioned, is aimed at inspecting the relationship between carrier name and the frequency of flight delays. ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -59.000 -17.000 -4.000 -2.837 6.013 60.000 Examining the dependent variable arr_delay, a main challenge arises as this predictor contains continuous values. To address this, the values are spitted into intervals of 3 minutes each. So that, the occurrence of arrival delays for each carrier can be quantified. Looking at the summary, it’s also possible to acknowledge that the median and mean reveals a prevalence of negative values deemed irrelevant, as the goal of this exercise is to inspect the relationship between the presence (not the absence) of arrival delays for each carrier. Thus, all values lower or equal to zero won’t be taken into consideration. Click on code preview to see how the data was counted and segmented by intervals of time. Code Preview interval &lt;-seq(1, upper_bound+0.5, by = 3) # 0.5 is needed as the count is asymmetrical. # Discretize arrival delays into intervals and count occurrences. delay_counts_1 &lt;- data_flight %&gt;% filter(arr_delay &gt; 0)%&gt;% mutate(delay_interval = cut(arr_delay, breaks = interval, right = T, include.lowest = T))%&gt;% group_by(delay_interval, carrier)%&gt;% summarise(delay_count = n()) The distribution of the newly generated count data across time intervals serves as the model’s dependent variables and it is assigned to the predictor delay_count. In the visualization below, you’ll observe that darker shades indicate a higher frequency of events per delay interval of time and carrier name. As for the independent variable, it’s evident from the plot that the values in carrier are nominal categorical. Which is okey, as independent variables can be of any type in Poisson Regression. Sometimes they must be encoded appropriately before fitting the model, for instance through dummy variables, one-hot encoding or factorization. However in this case, as the main focus is on examining the association between delay counts and carrier identity with no other predictor variables included, the categorical variable “carrier” can directly be implemented in the model . 3.2.2 Regression equation A few things can be derived from the assumption that the dependent variable in a Poisson-like distribution represent counts events occurring within a fixed boundary. For example, if those data points were to be represented in the Cartesian plane, they would also exist in a fixed space. In this scenario, a standard regression line, which may also predict negative values, is unsuitable for Poisson regression. Look at the example below: Notice that the line representing linear growth can very easily go below the origin at any given point while the starting point of the exponential line remains fixed. A non-linear relationship, typified by an exponential line, proves better-suited for this model. Consequently, the concept of exponential growth is included within the model’s regression equation, where a logarithmic transformation withholds the relationship between the dependent variable and the independent variable with its coefficients. \\[ y = e^{(\\beta_0 + \\beta_1x_1)} \\quad\\text{ or }\\quad log(y) = \\beta_0 + \\beta_1x_1 \\] It’s essential to recognize that (y) symbolizes the incidence rate of an event per unit of exposure, rather than the count of observed events. Replaced by the symbol (λ) or notated along with y∼Poisson(λ), (y) is understood as a rate parameter. This idea is pivotal, as concepts like the mean and variance hinge on it. For instance, since (λ) denotes the average rate of event occurrences within a fixed interval, the mean (expected value) remains equivalent to (λ). Consequently, as the mean increases, the range of possible outcomes expands. In other words, the distribution’s variability increases, which emphasizes the symmetrical association between the mean and the variance in Poisson Distribution. \\[ \\lambda = e^{(\\beta_0 + \\beta_1x)} \\quad \\quad \\text{or} \\quad \\quad y=e^{(\\beta_0 + \\beta_1x_1)} \\quad y\\sim Poisson(\\lambda) \\] Elements of this equation, such as the rate parameter (λ) and the coefficients (β0, β1), are automatically calculated through the implementation of the function GLM with family set to poisson glm(..., family = \"poisson\"). Ultimately, before starting training or prediction, the model will be fitted with all available data to evaluate the accuracy of the model and the relationship of the variables. poisson_model_eval &lt;- glm(delay_count ~ carrier, data = delay_counts, family = &quot;poisson&quot;) summary ## ## Call: ## glm(formula = delay_count ~ carrier, family = &quot;poisson&quot;, data = delay_counts) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.83468 0.09166 20.016 &lt; 2e-16 *** ## carrierAA 0.51139 0.11714 4.366 1.27e-05 *** ## carrierAS -1.83468 0.71302 -2.573 0.010079 * ## carrierB6 1.01891 0.10622 9.592 &lt; 2e-16 *** ## carrierDL 0.71866 0.11087 6.482 9.05e-11 *** ## carrierEV 1.14085 0.10465 10.901 &lt; 2e-16 *** ## carrierF9 -1.54700 0.50833 -3.043 0.002340 ** ## carrierFL -0.79859 0.20164 -3.960 7.48e-05 *** ## carrierHA -1.83468 1.00419 -1.827 0.067696 . ## carrierMQ 0.53408 0.11544 4.626 3.72e-06 *** ## carrierOO -1.83468 1.00419 -1.827 0.067696 . ## carrierUA 0.98072 0.10675 9.187 &lt; 2e-16 *** ## carrierUS 0.17185 0.12963 1.326 0.184948 ## carrierVX -0.76997 0.20709 -3.718 0.000201 *** ## carrierWN -0.27345 0.14404 -1.898 0.057639 . ## carrierYV -1.83468 0.71302 -2.573 0.010079 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 3245.5 on 198 degrees of freedom ## Residual deviance: 2563.9 on 183 degrees of freedom ## AIC: 3295 ## ## Number of Fisher Scoring iterations: 5 The model seems to effectively capture significant correlations among the variables, as indicated by the majority of carrier coefficients exhibiting statistically significant p-values. However, carrier US stands out with a coefficient surpassing 0.05, suggesting its potential minimal impact on delay occurrences. Thus, it might be prudent to contemplate excluding carrier US from the model. Nevertheless, before making any adjustments, let’s explore other potential factors that might be affecting the accuracy of the model. Notably, the coefficient estimates for carriers AS, OO, HA, and YV share an identical coefficient estimate of -1.83468 which is an unusual situation, unless these carriers are somehow grouped by a common circumstance. Upon reviewing the plot presented above, it’s apparent that these carriers are consistently associated with limited data, which is also evident by their relatively high standard errors (0.71302 for carriers AS and YV, and 1.00419 for carrier OO). The scarcity of data leads to less precise estimates, thus removing these coefficients might be a wise decision to improve the model’s reliability and predictive accuracy. delay_counts_new &lt;- delay_counts[!(delay_counts$carrier %in% c(&quot;AS&quot;, &quot;OO&quot;, &quot;YV&quot;, &quot;HA&quot;)), ] poisson_model_eval &lt;- glm(delay_count ~ carrier, data = delay_counts_new, family = &quot;poisson&quot;) summary ## ## Call: ## glm(formula = delay_count ~ carrier, family = &quot;poisson&quot;, data = delay_counts_new) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.83468 0.09166 20.016 &lt; 2e-16 *** ## carrierAA 0.51139 0.11714 4.366 1.27e-05 *** ## carrierB6 1.01891 0.10622 9.592 &lt; 2e-16 *** ## carrierDL 0.71866 0.11087 6.482 9.05e-11 *** ## carrierEV 1.14085 0.10465 10.901 &lt; 2e-16 *** ## carrierF9 -1.54700 0.50833 -3.043 0.002340 ** ## carrierFL -0.79859 0.20164 -3.960 7.48e-05 *** ## carrierMQ 0.53408 0.11544 4.626 3.72e-06 *** ## carrierUA 0.98072 0.10675 9.187 &lt; 2e-16 *** ## carrierUS 0.17185 0.12963 1.326 0.184948 ## carrierVX -0.76997 0.20709 -3.718 0.000201 *** ## carrierWN -0.27345 0.14404 -1.898 0.057639 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 3157.0 on 192 degrees of freedom ## Residual deviance: 2563.9 on 181 degrees of freedom ## AIC: 3275 ## ## Number of Fisher Scoring iterations: 5 The residual deviance of the revised model remains at 2563.9, indicating that the overall model fit remains consistent even after excluding carriers AS, OO, HA and YV from the dataset. The decrease in the AIC value from 3295 to 3279 suggests a slight enhancement in model fit following the removal of the three carriers. However, the standard error and p-value for all coefficients remain unchanged, so carrier US still lacks significant influence, as evidenced by its p-value of 0.184948. 3.3 Training &amp; Predicting Process Despite, GLM for Poisson regression doesn’t have specific built-in functions for training and testing like some machine learning algorithms, it can still be employed along with standard techniques for forecasting. Following the assesment of the data distribution, the subsequent phase involves dividing the dataset into training and testing subsets to evaluate the model’s performance. 80% of the data is allocated for GLM fitting while the remaining 20% is reserved for the evaluation the model’s predictive accuracy using the predict() function. Code Preview # Split the data (80% training, 20% testing) index &lt;- sample(1:nrow(delay_counts_new), 0.8*nrow(delay_counts_new)) training_data &lt;- delay_counts_new[index, ] testing_data &lt;- delay_counts_new[-index, ] poisson_model &lt;- glm(delay_count ~ carrier, data = training_data, family = &quot;poisson&quot;) predicted_counts &lt;- predict(poisson_model, newdata = testing_data, type = &quot;response&quot;) When assessing the precision of predictions generated by a Poisson regression model, various metrics can be utilized to measure the correspondence between the model’s predictions and the actual data. Nonetheless, let’s first initiate the process by gaining insight into the relationship between the predicted and the actual counts through a line plot.. From the observed visual data, disparities between the anticipated and observed counts stand out, particularly within the intervals [1,4] and [4,7]. Nonetheless, it is imperative to quantify the model’s performance using metrics such as the Mean Squared Error (MSE) and Mean Absolute Error (MAE) to assess the real efficiency of the current model. These metrics will be compared against a baseline which is made of the MSE and MAE of the training data’s delay counts. In the analysis, the following values were obtained: Code Preview baseline_predictions &lt;- rep(mean(training_data$delay_count), nrow(testing_data)) # Calculate MSE and MAE for the baseline model baseline_mse &lt;- mean((actual_counts - baseline_predictions)^2) baseline_mae &lt;- mean(abs(actual_counts - baseline_predictions)) # Calculate Model&#39;s MSE and MAE mse &lt;- mean((actual_counts - predicted_counts)^2) mae &lt;- mean(abs(actual_counts - predicted_counts)) ## [1] &quot;Baseline MSE: 687.829606540645&quot; ## [1] &quot;Model MSE: 662.875473599456&quot; ## [1] &quot;Baseline MAE: 13.9761904761905&quot; ## [1] &quot;Model MAE: 12.7993394506493&quot; The results of the evaluation indicate that the baseline model achieves a lower MSE and MAE compared to the predictive model. These findings suggest that the baseline model performs slightly better than the predictive model in terms of both MSE and MAE. However, the differences between the metrics are relatively small. Nevertheless, further investigation and refinement of the predictive model may be necessary to achieve significant improvements in performance, particularly for intervals [1,4] and [4,7]. 3.4 Strengths &amp; Limitations 3.4.1 Strengths Poisson regression stands out as an ideal method for examining phenomena such as occurrences of flight delays categorized by intervals, offering a robust framework for modeling events expressed as whole numbers. Its alignment with the Poisson distribution ensures accurate representation of count data dynamics, enhancing precision in modeling outcomes. Moreover, the model’s flexibility in handling various predictor types allows for versatile modeling approaches. 3.4.2 Limitations While powerful for count data analysis, comes with its share of limitations. The assumption of independence among events, while foundational, may not always reflect real-world scenarios accurately. Overdispersion, where the variance exceeds the mean, can inflate errors and compromise accuracy. Despite its flexibility in handling predictor variables, Poisson regression may struggle to capture complex relationships effectively, potentially limiting its predictive capabilities. Moreover, its sensitivity to outliers necessitates meticulous preprocessing to mitigate their influence on model stability. "],["binomial-linear-regression.html", "Chapter 4 Binomial Linear Regression 4.1 Overview 4.2 Algorithmic Framework 4.3 Training &amp; Predicting Process 4.4 Strengths and Limitations", " Chapter 4 Binomial Linear Regression By Eliana Perea Barreto 4.1 Overview Binomial regression is a type of generalized linear model used for a binary dependent variable (y), meaning a variable with two possible outcomes, often coded as 0 or 1. This model extends linear regression by applying a logistic function to estimate the probabilities of binary outcomes based on one or more predictor variables. 4.2 Algorithmic Framework 4.2.1 Data Nature Binomial regression, commonly known as logistic regression, is typically employed when the response variable assumes a binary form. However, as outlined in the introduction of this investigation, the goal here is to assess the relation between flight arrival delays and carrier names. In the revised framework, the response variable, arr_delay has continuous values. Thus it becomes imperative to appropriately transform its values into a binary format. In this new set up , a new variable arr_delay_binary is adopted as the response variable. This variable takes on the continuous values of arr_delay and assign 0 to delays lower or equal to 0 and 1 to delays greater than 1: \\[ \\text{arr_delay_binary} \\leq 0 \\quad \\text{ as &quot;on-time&quot; } = (0) \\quad | \\quad \\text{arr_delay_binary &gt; 0 } \\quad \\text{as delay} = (1) \\] Here’s a summary of the distribution of arr_delay_binary : Code Preview # Define lower and upper bounds for outliers Q1 &lt;- quantile(datos_flight$arr_delay, 0.25, na.rm = TRUE) Q3 &lt;- quantile(datos_flight$arr_delay, 0.75, na.rm = TRUE) lower_bound &lt;- Q1 - 1.5 * (Q3 - Q1) upper_bound &lt;- Q3 + 1.5 * (Q3 - Q1) # Replace outliers and NA values by the mean of the column mean_arr_delay &lt;- mean(datos_flight$arr_delay, na.rm = TRUE) datos_flight &lt;- datos_flight %&gt;% mutate(arr_delay = ifelse(is.na(arr_delay) | arr_delay &lt; lower_bound | arr_delay &gt; upper_bound, mean_arr_delay, arr_delay)) # Second mutate: Convert dep_delay to a binary variable datos_flight &lt;- datos_flight %&gt;% mutate(arr_delay_binary = ifelse(arr_delay &gt; 0, 1, 0)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 0.000 0.000 0.422 1.000 1.000 As delineated in the summary of the variable, the conversion of continuous data into a Boolean format (0 or 1) was accomplished seamlessly. This transformation is underscored by a mean value of 0, a minimum value of 0, and a maximum value of 1, with the absence of any NA values. Consequently, we can proceed to investigate how this response variable is distributed across all carriers, with a particular focus on discerning the proportion of delayed (1) versus non-delayed (0) instances. Notice that the carrier “OO” has a proportion of 100% delays. The reason behind this is that this carrier has only one entry in the dataset, which corresponds to 1. Such a circumstance prompts considerations regarding the distribution of data across carriers, especially in cases where data imbalances may influence the analysis. This concern is amplified if carriers with limited data entries, like “OO”, are considered next to carriers boasting larger datasets. ## ## 9E AA AS B6 DL EV F9 FL HA MQ OO UA US VX WN YV ## 276 504 3 818 747 787 8 52 7 401 1 844 299 71 176 6 ## Median of the counts: 226 Upon examination of the counts and median of the distribution, it becomes evident that several carriers fall significantly below the median. Carriers AS, F9, HA, OO, VX, and YV each have fewer than 50 samples, a quantity that may be deemed limited, as it is approximately five times lower than the median. This data imbalance could lead to the Generalized Linear Model (GLM) giving excessive importance to the minority class, possibly undermining prediction accuracy or inferences. To tackle the problem of low statistical power for airlines with minimal samples, they’ll be grouped under the category “Other,” . This way we can improve the model’s statistical power without sacrificing meaningful comparisons. Code Preview # Convert the table to a dataframe for easier manipulation carrier_counts_df &lt;- as.data.frame(carrier_counts) names(carrier_counts_df) &lt;- c(&quot;carrier&quot;, &quot;entries_count&quot;) # Identify airlines with fewer than 50 entries rare_airlines &lt;- carrier_counts_df$carrier[carrier_counts_df$entries_count &lt; 50] datos_flight$carrier_grouped &lt;- ifelse(datos_flight$carrier %in% rare_airlines, &quot;Other&quot;, datos_flight$carrier) # Create New dataset columns_to_keep &lt;- c(&quot;carrier_grouped&quot;,&quot;arr_delay&quot;, &quot;arr_delay_binary&quot;) binary_dataset &lt;- datos_flight[, columns_to_keep] 4.2.2 Regression Equation The goal of this study is to investigate the probability that the response variable  is 1 in regards to each carrier. Thus, this study is fundamentally a regression analysis based on probabilities, specifically focusing on the odds ratio. The odds ratio represents the likelihood of an event occurring relative to it not occurring. \\[ \\text{Odds} = \\frac{\\text{Probability of event}}{\\text{Probability of no event}} \\] The challenge of using odds as response variables in a linear model lies in their range from 0 to infinity, making them unable to naturally form a straight line relationship with predictors that range across all real numbers. To address this, a new strategy is proposed: predicting log-odds instead of odds. This transformation maps probabilities from the interval [0, 1] to the entire real line (−∞ to +∞). This allows the output to vary freely from (−∞ to +∞), which is essential for a linear relationship. Accordingly, the logistic regression model is expressed as follows: \\[ Logit(P(Y = 1|X))=ln(\\frac{P}{1−PP}​)= β_0​+β_1​ \\quad \\cdot \\quad (\\text{carrier name}) \\] Here, \\(log(\\frac{P}{1-P})\\) is the mathematical formula of the log-Odds which is used to calculate the probability of the event occurring. \\(\\beta_0\\) is the intercept and \\(\\beta_1\\) is the coefficients for the predictor variable x, carrier . The elements of this equation, including the natural logarithmic probability and the coefficients (β0, β1), are automatically computed by implementing the GLM function with the family parameter set to binomial glm(..., family = \"binomial\"). Below the model is fitted to assess its accuracy. binomial_model_eval &lt;- glm(arr_delay_binary ~ carrier_grouped, data = binary_dataset, family = &quot;binomial&quot;) Summary # Summary of the binomial model summary(binomial_model_eval) ## ## Call: ## glm(formula = arr_delay_binary ~ carrier_grouped, family = &quot;binomial&quot;, ## data = binary_dataset) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.27712 0.12154 -2.280 0.0226 * ## carrier_groupedAA -0.24218 0.15250 -1.588 0.1123 ## carrier_groupedB6 -0.02841 0.14063 -0.202 0.8399 ## carrier_groupedDL -0.36821 0.14389 -2.559 0.0105 * ## carrier_groupedEV 0.26950 0.14091 1.913 0.0558 . ## carrier_groupedFL 0.66659 0.30765 2.167 0.0303 * ## carrier_groupedMQ 0.30206 0.15732 1.920 0.0549 . ## carrier_groupedOther -0.12834 0.42596 -0.301 0.7632 ## carrier_groupedUA -0.14615 0.14045 -1.041 0.2981 ## carrier_groupedUS -0.13671 0.16950 -0.807 0.4199 ## carrier_groupedVX -0.09325 0.27031 -0.345 0.7301 ## carrier_groupedWN 0.11769 0.19402 0.607 0.5441 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 6809.3 on 4999 degrees of freedom ## Residual deviance: 6744.6 on 4988 degrees of freedom ## AIC: 6768.6 ## ## Number of Fisher Scoring iterations: 4 For several carriers (AA, B6, UA, US, VX, WN, Other), the coefficients obtained do not exhibit statistical significance. The residual deviance, which stands at 6756.4 in contrast to the null deviance of 6816.7, suggests that while the model accounts for a portion of the variability in flight delays, it does not capture all of it. Moreover, the “Other” category, representing carriers with limited samples, does not demonstrate statistical significance (p-value: 0.4092). I suspect that the variation in entry counts across carriers impacts the coefficient significance in this model. When one category has significantly more observations, it may dominate the model’s estimation, leading to biased estimates and inflated significance levels. Of more concern is the implication that the model has poor performance. However, without a comprehensive model evaluation, the true performance remains uncertain. Thus, we’ll assess the model’s effectiveness using evaluation metrics derived from a confusion matrix after the training and prediction process. 4.3 Training &amp; Predicting Process Before evaluating the model’s performance, it’s crucial to split the dataset into training and testing sets. Once the model is trained on the training set, we can assess its performance on the testing set to evaluate its ability to capture data patterns and make reliable predictions. To see how the model was fitted click on Model. set.seed(123) train_index &lt;- sample(1:nrow(binary_dataset), 0.8 * nrow(binary_dataset)) train_data &lt;- binary_dataset[train_index, ] test_data &lt;- binary_dataset[-train_index, ] Model # Train the logistic regression model on the training set logit_model &lt;- glm(arr_delay_binary ~ carrier_grouped, data = train_data, family = &quot;binomial&quot;) After fitting the logistic regression model, the predicted probabilities need to be converted into binary outcomes to compare them with the actual binary outcomes of arr_delay_binary. # Predict on the testing set predicted_probs &lt;- predict(logit_model, newdata = test_data, type = &quot;response&quot;) predicted_classes &lt;- ifelse(predicted_probs &gt; 0.5, 1, 0) 4.3.1 Model Evaluation This evaluation is grounded in the implementation of the confusion matrix, which offers a comprehensive breakdown of the model’s predictions in comparison to the actual outcomes. This matrix serves as the foundation for calculating various evaluation metrics, including accuracy, precision, recall, specificity, and the F1 score. By utilizing these metrics, we anticipate gaining insights into both the strengths and weaknesses of the model. ## predicted_classes ## 0 1 ## 0 526 47 ## 1 381 46 The confusion matrix breaks down predictions versus actual outcomes in binary classification scenarios, detailing counts for true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). TP represents correctly predicted delays (1), TN denotes correctly predicted non-delays (0). In our case, we have 526 TNs and 46 TPs. FP occurs when predicting a delay but the outcome is not, resulting in 47 instances, while FN arises when predicting no delay but experiencing a delay, with 381 occurrences. These values (TN = 526, FP = 47, FN = 381, TP = 46) are now implemented to calculate the metrics. The first metric, Accuracy, measures the proportion of correctly predicted outcomes out of the total number of predictions, providing an overall measure of correctness. ## Accuracy: 0.572 In this case, an accuracy of 0.572 indicates that approximately 57.2% of the model’s predictions are correct. This suggests that the model is correct more often than not, but it still makes a significant number of errors. Precision is the proportion of true positives out of all instances predicted as delays, indicating the model’s ability to avoid false positives. ## Precision: 0.4946237 A precision of 0.495 means that roughly 49.5% of the flights predicted as delays are actually delayed. This indicates that the model has a moderate rate of false positives, predicting delays that don’t occur about half the time. Recall, also known as sensitivity, is the proportion of true positives out of all actual delays. ## Recall: 0.1077283 A recall of 0.108 indicates that approximately 10.8% of the actual delays are correctly identified by the model. This low recall suggests that the model misses a large number of actual delays, indicating poor sensitivity to the delayed flights. Specificity is the proportion of true negatives out of all actual non-delays, focusing on the model’s ability to avoid false positives for non-delays. ## Specificity: 0.9179756 With a specificity of 0.918, roughly 91.8% of the non-delay flights are correctly identified by the model. This high specificity indicates that the model is good at identifying flights that will not be delayed, minimizing false positives. The F1 Score is the harmonic mean of precision and recall, providing a balance between these two metrics, especially useful when the classes are imbalanced. ## F1 Score: 0.1769231 An F1 Score of 0.177 suggests a poor balance between precision and recall, with the model performing poorly in identifying actual delays (low recall) and having a moderate number of false positives (moderate precision). The low F1 score indicates overall suboptimal performance, especially in identifying delayed flights. The analysis of the confusion matrix and derived metrics reveals notable findings regarding the model’s efficacy. While demonstrating a commendable ability to predict non-delayed flights, with a specificity of 91.8%, its performance in identifying actual delays is markedly deficient, as indicated by a low recall rate of 0.108. Despite achieving an overall accuracy of 57.2%, the model’s disproportionate precision and recall resulted in an F1 Score of 0.177, which highlights the model’s suboptimal capability in detecting delayed flights., exacerbated by the inherent class imbalance within the dataset, skewed towards non-delays. The model’s sub-optimal performance might also stem from short availability of features. In this instance, the model solely relied on the “carrier_grouped” variable for predicting flight delays, potentially neglecting other pertinent predictors. The subsequent section will conduct a comprehensive evaluation of the model’s strengths and limitations to inform future refinement efforts. 4.4 Strengths and Limitations 4.4.1 Strengths The GLM to binomial modeling technique presents several notable strengths, rendering it an appropriate choice for analyzing vast datasets such as flight data. Its simplicity and computational efficiency facilitate model implementation and interpretation. Moreover, its robustness to outliers, attributed to the flexibility of the log-odds, enhances its reliability compared to more sensitive models like Simple Linear Regression. Despite its limitations, evidenced by an accuracy of 57.2%, the model demonstrates reasonable performance despite the complexities found in the data. 4.4.2 Limitations The GLM to binomial, while straightforward, may struggle to capture complex patterns due to its simplistic nature compared to more advanced techniques like decision trees or neural networks. Its assumption of a linear relationship between predictors and outcomes may limit its ability to model nonlinear relationships. This model might also face challenges in generalizing to unseen data as it seems to be very sensitivity to imbalances in sample sizes impacting the model’s predictive power. To improve performance, exploring alternative algorithms and incorporating additional features might be needed to enhance its robustness. In summary, while GLM to binomial explains some variability in flight delays, its predictive power may be constrained by the model’s simplicity and the exclusion of potentially relevant predictors. "],["support-vector-machine.html", "Chapter 5 Support Vector Machine 5.1 Introduction 5.2 Data Preparation 5.3 Training and Test Split 5.4 Model Evaluation 5.5 Conclusion", " Chapter 5 Support Vector Machine By Sheptim Veseli 5.1 Introduction In our analysis, we apply the SVM algorithm to predict the log-transformed arrival delays of flights based on the carrier variable. The log transformation of arrival delays helps to stabilize variance and normalize the distribution, making it more suitable for regression modeling. The SVM model is trained on a subset of the flight data and evaluated on a separate test set to assess its predictive performance. 5.2 Data Preparation The dataset was first prepared by removing any missing values to ensure the integrity of the analysis. The ‘carrier’ variable, representing different airlines, was converted into a factor to facilitate its use in the SVM model. # Data preparation flights_subset &lt;- na.omit(flights_subset) flights_subset$carrier &lt;- as.factor(flights_subset$carrier) 5.3 Training and Test Split To evaluate the model’s performance, the dataset was split into training and test sets, with 80% of the data used for training the model and the remaining 20% reserved for testing. # Set seed for reproducibility set.seed(123) # Split the data into training and test sets train_index &lt;- createDataPartition(flights_subset$log_arr_delay, p = 0.8, list = FALSE) train_data &lt;- flights_subset[train_index, ] test_data &lt;- flights_subset[-train_index, ] 5.3.1 SVM Model Training The SVM model was trained using the svm function from the e1071 package, with the log-transformed arrival delay as the dependent variable and the carrier as the independent variable. The model employed the radial basis function (RBF) kernel, which is well-suited for capturing non-linear relationships. # Train the SVM model svm_model &lt;- svm(log_arr_delay ~ carrier, data = train_data, type = &quot;eps-regression&quot;) Summary Preview # Print the model summary print(svm_model) ## ## Call: ## svm(formula = log_arr_delay ~ carrier, data = train_data, type = &quot;eps-regression&quot;) ## ## ## Parameters: ## SVM-Type: eps-regression ## SVM-Kernel: radial ## cost: 1 ## gamma: 0.06666667 ## epsilon: 0.1 ## ## ## Number of Support Vectors: 1530 The SVM model parameters were as follows: SVM-Type: epsilon-regression SVM-Kernel: radial Cost (C): 1 Gamma: 0.0667 Epsilon: 0.1 Number of Support Vectors: 1530 5.4 Model Evaluation The model’s performance was evaluated on the test set. The Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) were calculated to quantify the accuracy of the predictions. ## Mean Squared Error: 1.588177 ## Root Mean Squared Error: 1.260229 The results were: Mean Squared Error (MSE): 1.588 Root Mean Squared Error (RMSE): 1.260 These metrics indicate the average squared difference and the average error between the predicted and actual log-transformed arrival delays, respectively. 5.4.1 Result Interpretation The scatter plot below illustrates the relationship between the actual and predicted log-transformed arrival delays. The red line represents the ideal scenario where the predicted values perfectly match the actual values. The proximity of the points to this line indicates the accuracy of the model’s predictions. 5.4.2 Discussion The SVM model, with its radial basis function kernel, effectively captured the non-linear relationship between the carrier and the log-transformed arrival delay. The model’s performance, as indicated by the RMSE, suggests that while the SVM provides reasonably accurate predictions, there is still room for improvement. The scatter plot reveals that the predictions are closely aligned with the actual values, though some variability remains unaccounted for. 5.5 Conclusion The application of Support Vector Machines to predict flight arrival delays demonstrates the utility of this machine learning technique in handling complex, non-linear relationships. The analysis shows that certain carriers have a measurable impact on arrival delays, though the low R-squared value in the initial linear regression suggests that other factors, such as weather conditions or airport congestion, likely play significant roles. Future work could involve incorporating additional predictors and exploring other machine learning algorithms to further enhance the model’s predictive power. "],["generalized-additive-model.html", "Chapter 6 Generalized Additive Model 6.1 Introduction 6.2 Data Preparation 6.3 Data Splitting &amp; Model Fitting 6.4 Conclusion", " Chapter 6 Generalized Additive Model By Sheptim Veseli 6.1 Introduction The Generalized Additive Model (GAM) represents an advanced statistical approach designed to capture non-linear relationships between predictor and response variables. GAMs extend linear models by allowing non-linear functions of predictor variables while maintaining additivity. This flexibility makes GAMs particularly useful in scenarios where the relationship between variables is complex and cannot be adequately modeled with simple linear terms. In this report, we apply GAM to predict the log-transformed flight arrival delays using the ‘carrier’ variable from the nycflights13 dataset. This analysis aims to assess the effectiveness of GAM in modeling flight delays and uncover patterns associated with different airlines. 6.2 Data Preparation The dataset used in this analysis is a subset of the nycflights13 dataset, consisting of 5000 randomly selected flights. The following steps were undertaken to prepare the data: # Set random seed for reproducibility set.seed(123) # Randomly select 5000 rows and use them to subset original data selected_indices &lt;- sample(1:nrow(flights), 5000, replace = FALSE) flights_subset &lt;- flights[selected_indices, ] A random sample of 5000 rows was selected from the original dataset to create a manageable subset for analysis. Handling Missing Values: Rows with missing values in critical variables such as dep_time, arr_time, arr_delay, tailnum, and air_time were removed to ensure data integrity. Removing Negative Arrival Delays: Rows with negative values for arr_delay were eliminated as they do not represent valid flight delay times. Code Preview # Remove rows with missing values in key variables flights_subset &lt;- flights_subset[complete.cases(flights_subset$dep_time, flights_subset$arr_time, flights_subset$arr_delay, flights_subset$tailnum, flights_subset$air_time), ] # Remove NA and negative values from arrival delay time (arr_delay) flights_subset &lt;- flights_subset[complete.cases(flights_subset$arr_delay) &amp; flights_subset$arr_delay &gt;= 0, ] 6.2.1 Log Transformation The arr_delay variable was log-transformed to normalize its distribution and stabilize variance. One was added to avoid log(0) issues. # Apply logarithmic transformation to arrival delay time (arr_delay) flights_subset$log_arr_delay &lt;- log(flights_subset$arr_delay + 1) # Adding 1 to avoid log(0) issues # Convert carrier to factor flights_subset$carrier &lt;- as.factor(flights_subset$carrier) 6.3 Data Splitting &amp; Model Fitting The data was split into training (80%) and test (20%) sets for model evaluation. This step ensures that the model’s performance is evaluated on unseen data, providing a more realistic assessment of its predictive capabilities. # Split the data into training and test sets set.seed(123) # Set seed for reproducibility train_index &lt;- createDataPartition(flights_subset$log_arr_delay, p = 0.8, list = FALSE) train_data &lt;- flights_subset[train_index, ] test_data &lt;- flights_subset[-train_index, ] A Generalized Additive Model was fitted to the training data with the following specifications: Response Variable: log_arr_delay Predictor Variable: carrier (as a factor with a smooth term) The model formula used was: log_arr_delay∼s(carrier,bs=“re”) log_arr_delay∼s(carrier,bs=“re”) where s(carrier, bs = “re”) indicates a smooth term for the carrier variable using a random effects basis spline. # Fit a Generalized Additive Model gam_model &lt;- gam(log_arr_delay ~ s(carrier, bs = &quot;re&quot;), data = train_data) 6.3.1 Model Summary The summary of the fitted GAM is as follows: Family: Gaussian Link Function: Identity Intercept: 2.88605 (Std. Error: 0.06721, p &lt; 2e-16) Smooth Terms: s(carrier): edf = 6.945, Ref.df = 14, F = 1.4, p = 0.00212 Model Performance: Adjusted R-squared: 0.011 Deviance Explained: 1.52% Generalized Cross-Validation (GCV) Score: 1.6482 Scale Estimate: 1.6402 Number of Observations: 1643 Code Preview # Print model summary summary(gam_model) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## log_arr_delay ~ s(carrier, bs = &quot;re&quot;) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.88605 0.06721 42.94 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(carrier) 6.945 14 1.4 0.00212 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.011 Deviance explained = 1.52% ## GCV = 1.6482 Scale est. = 1.6402 n = 1643 The intercept of 2.88605 represents the baseline log-transformed arrival delay when the carrier effect is not considered. The significant smooth term for the carrier variable (p = 0.00212) indicates that different airlines have different patterns of arrival delays. The effective degrees of freedom (edf) for the carrier term suggests a moderately complex relationship. However, the adjusted R-squared value of 0.011 and the deviance explained of 1.52% indicate that the carrier variable alone does not explain much of the variability in arrival delays. This low explanatory power suggests that other factors not included in this model, such as weather conditions, airport congestion, and specific aircraft issues, are likely to play a significant role in influencing arrival delays. These findings align with expectations, as flight delays are typically influenced by a multitude of factors beyond the airline carrier alone. 6.3.2 Model Evaluation The model was evaluated on the test set, yielding the following performance metrics: ## Mean Squared Error: 1.576027 ## Root Mean Squared Error: 1.255399 The MSE and RMSE indicate the average squared difference and the square root of this average, respectively, between the actual and predicted log-transformed arrival delays. These metrics provide a quantitative measure of the model’s prediction accuracy. The RMSE value of approximately 1.255 suggests that the model’s predictions are, on average, within 1.255 units of the actual log-transformed arrival delays. Next,the scatterplot below compares the actual log-transformed arrival delays with the predicted values from the GAM model. The red line represents the ideal fit where predicted values equal actual values. The scatterplot indicates a spread around the red line, reflecting the model’s predictions. The spread suggests variability in prediction accuracy, which is expected given the low R-squared value. Summary Preview summary(gam_model) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## log_arr_delay ~ s(carrier, bs = &quot;re&quot;) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.88605 0.06721 42.94 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(carrier) 6.945 14 1.4 0.00212 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.011 Deviance explained = 1.52% ## GCV = 1.6482 Scale est. = 1.6402 n = 1643 6.4 Conclusion The application of GAM to predict flight arrival delays based on the carrier variable highlights the significance of airline-specific patterns in arrival delays. However, the low explanatory power of the model underscores the complexity of factors influencing flight delays. While the GAM captured some carrier-specific trends, it is evident that additional variables such as weather conditions, airport traffic, flight distance, and aircraft-specific issues need to be included to improve predictive performance. Future research should focus on incorporating these additional predictors to develop a more comprehensive model. "],["neural-network.html", "Chapter 7 Neural Network 7.1 Overview 7.2 Algorithmic Framework 7.3 Training &amp; Predicting Process 7.4 Strengths &amp; Limitations", " Chapter 7 Neural Network By Eliana Perea Barreto 7.1 Overview Neural networks are computational models inspired by the workings of the human brain. The base-units of these networks are neurons, which are essentially units of value that exist within a system of layers. In each layer, the neurons are properly activated and managed to determine the strength and direction of the signals transmitted between them. The process of activating neurons to achieve coherent outputs is governed by weights and biases, which control the flow and transformation of input data through the network. 7.2 Algorithmic Framework The neural network consists of neurons, weights, biases, and layers. These elements collectively form its architecture. The quantity of these components depend on the model’s complexity and desired precision, ranging from simple (a few layers and neurons) to highly intricate structures (thousands of neurons and numerous layers). In this specific case, a simple neural network is employed to predict flights arrival delay (arr_delay) based on carrier names (carrier). At the core of the model, there are 4 layers: the input layer (x) with 16 neurons (one for each carrier), 2 hidden layers (z_1, z_2) with 3 and 2 neurons respectively, and the output layer (y) with one neuron. Layers # Initialize layers input_size &lt;- 16 hidden_size1 &lt;- 3 hidden_size2 &lt;- 2 output_size &lt;- 1 As carrier names are categorical variables, they must be encoded into numeric format. For that, one-hot encoding is implemented to convert the categorical carrier feature into multiple binary features. The goal is to prevent the model from assuming any ordinal relationship between the categories. Each row will have a 1 in the column corresponding to its carrier and 0 in the others. One-Hot Encode # One-Hot Encode the &#39;carrier&#39; variable one_hot &lt;- model.matrix(~ carrier - 1, data = data) data &lt;- cbind(data, one_hot) data$carrier &lt;- NULL Information is transmitted in this model through the activation of the neurons in each layer. Now, imagine activating all neurons simultaneously would result in a chaotic mix of unrelated information. To address this, “weights”; values tare set randomly at the beginning of the process but are adjusted over time to minimize prediction errors. As Neural networks operate through matrix operations, 3 weight matrices are generated to contain the weighted values of each layer. Weights # Initialize weights W1 &lt;- matrix(rnorm(input_size * hidden_size1), nrow=input_size, ncol=hidden_size1) W2 &lt;- matrix(rnorm(hidden_size1 * hidden_size2), nrow=hidden_size1, ncol=hidden_size2) W3 &lt;- matrix(rnorm(hidden_size2 * output_size), nrow=hidden_size2, ncol=output_size) As the information flows between the network’s layers through the activation of neurons with weights, the biases (b) supports each layer by accounting for any inherent offsets in the data, allowing the model to better fit the training examples. Bias # Initialize biases b1 &lt;- matrix(rnorm(hidden_size1), nrow=1, ncol=hidden_size1) b2 &lt;- matrix(rnorm(hidden_size2), nrow=1, ncol=hidden_size2) b3 &lt;- matrix(rnorm(output_size), nrow=1, ncol=output_size) Below is a visual representation of the architecture of this neural network. For simplicity, the input layer is depicted with only 4 neurons. However, it is important to note that this model actually starts with 16 neurons in the input layer: 7.3 Training &amp; Predicting Process Normally in a training/testing predicting process the the data is split in 2 sets. 80% of the data is allocated for model fitting while the remaining 20% is reserved for the evaluation the model’s predictive accuracy. # Split the data (80% training, 20% testing) indices &lt;- sample(1:nrow(datat), 0.8 * nrow(data)) train_data &lt;- data_flight[indices, ] test_data &lt;- data_flight[-indices, ] 7.3.1 Feed-forward Algorithm Referring back to the visual representation of the model’s structure from the previous chapter, it’s possible conceptualize the mathematical formula for the first hidden layer (\\(Z^{1}\\)) as a linear combination of neurons in the input layer (\\(X\\)) the weights’ matrix (\\(W^{1}\\)) plus the bias \\(b^{1}\\): \\[ Z^{1} = X \\cdot W^{1} + b^{1} \\] This formula is at the core of the forward pass where transmitted inputs through the network’s layer result in a predicted output. As the process moves forwards, the components of that formula are replaced by values corresponding to each layer. Additionally, the output of each layer must be normalized before it is transmitted to the next layer, in order to produce a cohesive result and also to facilitate the network’s ability to generalize. This normalization process is carried out by an activation function such Sigmoid or ReLU. In this specific case, Sigmoid squishification is implemented to take the weighted sum of the neurons and squish it into a range between 0 and 1. Basically, in this logistic function negative inputs end up close to zero, positive inputs get closed to one.\\[ \\sigma(x) = \\frac{1}{1 + e^{-x}} \\] When \\(x\\) is a large negative number, \\(e^{-x}\\) becomes very large. Example, \\(x = -10, e^{-(-10)} = e^{10}\\). Then, this value will do the fraction \\(\\frac{1}{1+e^{10}}\\) very small, approaching zero. Sigmoid # Sigmoid activation function sigmoid &lt;- function(x) { 1 / (1 + exp(-x)) } With all components defined, the forward pass can be initiated. Additionally, a Cost function is set to measure the network’s performance. This Cost function (also called Loss function) quantifies the error between the predicted output (\\(\\hat{y}\\)) and the actual output (\\(y\\)). In this exercise, the Cost function is the Mean Squared Error (MSE). \\[ L(\\hat{y}, y) = (\\hat{y} - y)^2 \\] # Feed-forward input &lt;- train_data[, -ncol(train_data)] Z1_train &lt;- as.matrix(input) %*% W1 + matrix(b1, nrow=nrow(train_data), ncol=ncol(b1)) A1_train &lt;- sigmoid(Z1_train) Z2_train &lt;- A1_train %*% W2 + matrix(b2, nrow = nrow(A1_train), ncol = ncol(b2)) A2_train &lt;- sigmoid(Z2_train) # No activation function for the last layer as this is a regression problem Z3_train &lt;- A2_train %*% W3 + matrix(b3, nrow = nrow(A2_train), ncol = ncol(b3)) predicted_output_train &lt;- Z3_train # Calculate mean squared error for training data cost_train &lt;- mean((predicted_output_train - train_data$arr_delay)^2) ## Cost previous to iterations: 1973.661 ## AVG Cost per sample: 0.5068467 The high total cost indicates that the predictions are far from the actual values, which is expected since the model hasn’t undergone any training iterations yet. The learning abilities of Neural Networks highly rely in an iterative process to adjust the weights. To enhance the model’s performance, we need to define the number of training cycles, or epochs. Here, we set the number of epochs to 10, but this can be adjusted based on the model’s prediction accuracy. epochs &lt;- 10 Additionally all the operations presented till now constitute only one section of the learning process. The cost is high because the model hasn’t received any clues to establish the correct direction to minimize the Cost, which is the ultimate goal of this process. To achieve it, the gradient of the cost function must be calculated. 7.3.2 Backpropagation Self-training in machine learning refers to a model’s ability to iteratively analyze input data and learn to improve performance. In Backpropagation, the process is carried out backward, transmitting the error between predicted and actual outputs to previous layers. This adjusts weights and biases, minimizing the cost function. Minimization occurs when the model identifies the direction to reduce the cost, guided by the gradient of the cost function. If the slope is positive, moving in the negative gradient direction decreases the cost, and viceversa if the slope is negative. Mathematically, partial derivatives determine the gradient. The partial derivative of the cost function with respect to weights is denoted as \\(\\frac{\\partial Cost}{ \\partial W^{(L)}}\\). The weights are related to the values of a previous layer’s weighted input \\(Z^{(L)}\\)and its activation function \\(a^{(L)}\\) The derivative of \\(Z^{(L)}\\) with respect to \\(W^{(L)}\\) is \\(\\frac{\\partial Z^{(L)}}{\\partial W^{(L)}} = a^{(L-1)}\\) The derivative of the activation function \\(a^{(L)}\\) with respect to \\(Z^{(L)}\\) is \\(\\frac{\\partial a^{(L)}}{\\partial Z^{(L)}} = \\sigma&#39;(Z^{(L)})\\) The derivative of the cost with respect to the activation \\(a^{(L)}\\) is \\(\\frac{\\partial Cost}{\\partial a^{(L)}} = 2 (a^{(L)} - y)\\). Therefore, the formula for Backpropagation can be defined as follows: \\[ \\frac{\\partial Cost}{\\partial W^{(L)}} = \\frac{\\partial Z^{(L)}}{\\partial W^{(L)}} \\cdot \\frac{\\partial a^{(L)}}{\\partial Z^{(L)}} \\cdot \\frac{\\partial Cost }{\\partial a^{(L)}} \\] Before initiating the code for Backpropagation, the derivative of the sigmoid function is defined: Sigmoid Derivative # Derivative of sigmoid function sigmoid_derivative &lt;- function(x) { sigmoid(x) * (1 - sigmoid(x)) }   dZ3_train &lt;- 2 * (predicted_output_train - train_data$arr_delay) dW3 &lt;- t(A2_train) %*% dZ3_train # First multiplication dA2_train &lt;- dZ3_train %*% t(W3) # First error propagation dZ2_train &lt;- dA2_train * sigmoid_derivative(Z2_train) dW2 &lt;- t(A1_train) %*% dZ2_train # Second multiplication dA1_train &lt;- dZ2_train %*% t(W2) # Second error propagation dZ1_train &lt;- dA1_train * sigmoid_derivative(Z1_train) dW1 &lt;- t(input) %*% dZ1_train # Third multiplication The process is concluded with the update of the weights which, in gradient descent, is given by the formula: \\[W^{(L)} \\leftarrow W^{(L)} - \\eta \\frac{\\partial Cost}{\\partial W^{(L)}}\\] where \\(\\eta\\) is the learning ratio, set to 0.01 in this specific case. The learning rate controls the size of the adjustments made to the model’s weights during training. A learning rate of 0.01 indicates that the weights are updated in small increments, which helps in gradually minimizing the error without overshooting the optimal values. learning_rate = 0.01 Update # Update of weights and bias W3 &lt;- W3 - learning_rate * dW3 b3 &lt;- b3 - learning_rate * db3 W2 &lt;- W2 - learning_rate * dW2 b2 &lt;- b2 - learning_rate * db2 W1 &lt;- W1 - learning_rate * dW1 b1 &lt;- b1 - learning_rate * db1 With that, the explanation of the neural network training process is concluded. The remaining task is to iterate over this process repeatedly to refine the model’s performance. In our case, the model will undergo 10 iterations, as the number of epochs was initially set to that value. To view the implementation of the full code with these iterations, click on Code Preview. Code Preview # Training loop function with adjusted learning rate train_model &lt;- function(train_data, W1, W2, W3, b1, b2, b3, epochs, learning_rate) { for (epoch in 1:epochs) { input &lt;- train_data[, -ncol(train_data)] Z1_train &lt;- as.matrix(input) %*% W1 + matrix(b1, nrow=nrow(train_data), ncol=ncol(b1)) A1_train &lt;- sigmoid(Z1_train) Z2_train &lt;- A1_train %*% W2 + matrix(b2, nrow = nrow(A1_train), ncol = ncol(b2)) A2_train &lt;- sigmoid(Z2_train) Z3_train &lt;- A2_train %*% W3 + matrix(b3, nrow = nrow(A2_train), ncol = ncol(b3)) predicted_output_train &lt;- Z3_train # Calculate mean squared error for training data loss_train &lt;- mean((predicted_output_train - train_data$arr_delay)^2) dZ3_train &lt;- 2 * (predicted_output_train - train_data$arr_delay) dW3 &lt;- t(A2_train) %*% dZ3_train # First multiplication dA2_train &lt;- dZ3_train %*% t(W3) # First error propagation dZ2_train &lt;- dA2_train * sigmoid_derivative(Z2_train) dW2 &lt;- t(A1_train) %*% dZ2_train # Second multiplication dA1_train &lt;- dZ2_train %*% t(W2) # Second error propagation dZ1_train &lt;- dA1_train * sigmoid_derivative(Z1_train) dW1 &lt;- t(input) %*% dZ1_train # Third multiplication # Bias db3 &lt;- colSums(dZ3_train) db2 &lt;- colSums(dZ2_train) db1 &lt;- colSums(dZ1_train) # Gradient Clipping. to prevent gradient becoming to large clip_value &lt;- 5000 dW3 &lt;- pmax(pmin(dW3, clip_value), -clip_value) dW2 &lt;- pmax(pmin(dW2, clip_value), -clip_value) dW1 &lt;- pmax(pmin(dW1, clip_value), -clip_value) db3 &lt;- pmax(pmin(db3, clip_value), -clip_value) db2 &lt;- pmax(pmin(db2, clip_value), -clip_value) db1 &lt;- pmax(pmin(db1, clip_value), -clip_value) # Update of weights and bias W3 &lt;- W3 - learning_rate * dW3 b3 &lt;- b3 - learning_rate * db3 W2 &lt;- W2 - learning_rate * dW2 b2 &lt;- b2 - learning_rate * db2 W1 &lt;- W1 - learning_rate * dW1 b1 &lt;- b1 - learning_rate * db1 # Print loss for monitoring cat(&quot;Epoch:&quot;, epoch, &quot; - Loss (Training):&quot;, loss_train, &quot;\\n&quot;) } list(W1 = W1, W2 = W2, W3 = W3, b1 = b1, b2 = b2, b3 = b3) } # Call the train_model function with the adjusted learning rate updated_parameters &lt;- train_model(train_data, W1, W2, W3, b1, b2, b3, epochs, learning_rate) ## Epoch: 1 - Loss (Training): 2002.533 ## Epoch: 2 - Loss (Training): 1939.68 ## Epoch: 3 - Loss (Training): 1837.457 ## Epoch: 4 - Loss (Training): 1739.89 ## Epoch: 5 - Loss (Training): 1678.186 ## Epoch: 6 - Loss (Training): 1873.737 ## Epoch: 7 - Loss (Training): 2213.296 ## Epoch: 8 - Loss (Training): 1621.107 ## Epoch: 9 - Loss (Training): 1581.032 ## Epoch: 10 - Loss (Training): 1541.294 ## Epoch: 11 - Loss (Training): 1501.356 ## Epoch: 12 - Loss (Training): 1462.962 ## Epoch: 13 - Loss (Training): 1600.802 ## Epoch: 14 - Loss (Training): 1394.36 ## Epoch: 15 - Loss (Training): 1790.194 ## Epoch: 16 - Loss (Training): 1392.42 ## Epoch: 17 - Loss (Training): 1728.941 ## Epoch: 18 - Loss (Training): 1301.008 ## Epoch: 19 - Loss (Training): 1695.775 ## Epoch: 20 - Loss (Training): 1253.605 ## Epoch: 21 - Loss (Training): 1659.647 ## Epoch: 22 - Loss (Training): 1221.139 ## Epoch: 23 - Loss (Training): 1631.177 ## Epoch: 24 - Loss (Training): 1163.037 ## Epoch: 25 - Loss (Training): 1654.488 ## Epoch: 26 - Loss (Training): 1135.523 ## Epoch: 27 - Loss (Training): 1635.576 ## Epoch: 28 - Loss (Training): 1110.887 ## Epoch: 29 - Loss (Training): 1618.336 ## Epoch: 30 - Loss (Training): 1092.078 ## Epoch: 31 - Loss (Training): 1527.634 ## Epoch: 32 - Loss (Training): 1089.671 ## Epoch: 33 - Loss (Training): 1504.699 ## Epoch: 34 - Loss (Training): 1073.576 ## Epoch: 35 - Loss (Training): 1483.005 ## Epoch: 36 - Loss (Training): 1058.288 ## Epoch: 37 - Loss (Training): 1467.154 ## Epoch: 38 - Loss (Training): 1049.159 ## Epoch: 39 - Loss (Training): 1451.484 ## Epoch: 40 - Loss (Training): 1038.714 ## Epoch: 41 - Loss (Training): 1439.32 ## Epoch: 42 - Loss (Training): 1040.032 ## Epoch: 43 - Loss (Training): 1428.715 ## Epoch: 44 - Loss (Training): 1037.947 ## Epoch: 45 - Loss (Training): 1416.46 ## Epoch: 46 - Loss (Training): 1028.57 ## Epoch: 47 - Loss (Training): 2336.064 ## Epoch: 48 - Loss (Training): 1097.746 ## Epoch: 49 - Loss (Training): 1085.115 ## Epoch: 50 - Loss (Training): 988.8929 ## Epoch: 51 - Loss (Training): 1034.588 ## Epoch: 52 - Loss (Training): 1088.998 ## Epoch: 53 - Loss (Training): 1024.318 ## Epoch: 54 - Loss (Training): 987.7465 ## Epoch: 55 - Loss (Training): 986.9891 ## Epoch: 56 - Loss (Training): 1103.72 ## Epoch: 57 - Loss (Training): 976.7364 ## Epoch: 58 - Loss (Training): 1098.627 ## Epoch: 59 - Loss (Training): 969.0878 ## Epoch: 60 - Loss (Training): 1097.695 ## Epoch: 61 - Loss (Training): 960.647 ## Epoch: 62 - Loss (Training): 1099.25 ## Epoch: 63 - Loss (Training): 952.2167 ## Epoch: 64 - Loss (Training): 1102.652 ## Epoch: 65 - Loss (Training): 945.6094 ## Epoch: 66 - Loss (Training): 1006.211 ## Epoch: 67 - Loss (Training): 939.0979 ## Epoch: 68 - Loss (Training): 1110.306 ## Epoch: 69 - Loss (Training): 932.8845 ## Epoch: 70 - Loss (Training): 1113.977 ## Epoch: 71 - Loss (Training): 929.0473 ## Epoch: 72 - Loss (Training): 1013.099 ## Epoch: 73 - Loss (Training): 914.9852 ## Epoch: 74 - Loss (Training): 1047.083 ## Epoch: 75 - Loss (Training): 914.3144 ## Epoch: 76 - Loss (Training): 1037.97 ## Epoch: 77 - Loss (Training): 914.2082 ## Epoch: 78 - Loss (Training): 1155.68 ## Epoch: 79 - Loss (Training): 912.1165 ## Epoch: 80 - Loss (Training): 1031.937 ## Epoch: 81 - Loss (Training): 910.0517 ## Epoch: 82 - Loss (Training): 1028.026 ## Epoch: 83 - Loss (Training): 909.1717 ## Epoch: 84 - Loss (Training): 1018.629 ## Epoch: 85 - Loss (Training): 908.0742 ## Epoch: 86 - Loss (Training): 1014.12 ## Epoch: 87 - Loss (Training): 905.119 ## Epoch: 88 - Loss (Training): 1011.756 ## Epoch: 89 - Loss (Training): 905.4758 ## Epoch: 90 - Loss (Training): 1008.495 ## Epoch: 91 - Loss (Training): 904.4414 ## Epoch: 92 - Loss (Training): 1001.232 ## Epoch: 93 - Loss (Training): 927.811 ## Epoch: 94 - Loss (Training): 999.2898 ## Epoch: 95 - Loss (Training): 904.6963 ## Epoch: 96 - Loss (Training): 995.6421 ## Epoch: 97 - Loss (Training): 925.984 ## Epoch: 98 - Loss (Training): 994.6018 ## Epoch: 99 - Loss (Training): 897.3991   Initially, with 10 epochs and a learning rate of 0.01, the training process showed signs of divergence.This means that the loss was increasing exponentially instead of decreasing, which is the opposite of what should ideally happen. To address this issue, the learning rate was adjusted to 0.0002 to ensure more gradual updates to the model weights. Additionally, the weight matrices were normalized with a mean of 0 and a standard deviation of 0.01. The number of epochs was extended to 99 and gradient clipping was set to prevent the gradients from getting too large. Here are some observations based on the provided results: Convergence: The loss was decreasing rapidly after the clip value was set to 5000. The last achieve value is around 897.3. This indicates that the model has converged. Further training epochs might be needed to significant improvements in the loss. Stability: Generally the loss has a tendency to decrease, however there are intermittent value fluctuations. Learning Rate: The chosen learning rate of 0.0002 seems to be appropriate for the training process, allowing the model to make consistent progress in reducing the loss over the epochs. Effectiveness: The final loss achieved after 99 epochs, indicating that the model has learned from the data effectively. A Feed-forward architecture is created to assess the model’s predictive abilities with the testing data. Predict model predict_model &lt;- function(test_data, W1, W2, W3, b1, b2, b3) { input &lt;- test_data[, -ncol(test_data)] Z1_test &lt;- as.matrix(input) %*% W1 + matrix(b1, nrow=nrow(test_data), ncol=ncol(b1)) A1_test &lt;- sigmoid(Z1_test) Z2_test &lt;- A1_test %*% W2 + matrix(b2, nrow=nrow(A1_test), ncol=ncol(b2)) A2_test &lt;- sigmoid(Z2_test) Z3_test &lt;- A2_test %*% W3 + matrix(b3, nrow=nrow(A2_test), ncol=ncol(b3)) predicted_output_test &lt;- Z3_test return(predicted_output_test) } ## Mean Squared Error on Test Data: 1190.679   The model exhibits promise in capturing the variance within the data, as indicated by the substantial decrease in loss during both training and testing phases. This implies that the model has the capacity to learn from the provided data and make predictions effectively. The rapid decline in loss throughout the established epochs suggests that further iterations could enhance the model’s capabilities, indicating room for improvement with additional training epochs. Moreover, fluctuations observed in loss during both training and testing phases suggest potential instability or heightened sensitivity, likely stemming from the relatively small dataset size. With fewer data points, the model may be more vulnerable to noise or outliers, increasing the risk of overfitting. I tried to address this issue by normalizing the training and testing data, however the fluctuations persisted. This highlights the need for further exploration and refinement of the model architecture. Additional regularization techniques might be considered, such as fine-tuning hyperparameters or employing methods like Lasso regression to effectively mitigate the issue of fluctuation and improve the model’s performance. 7.4 Strengths &amp; Limitations 7.4.1 Strengths Neural networks can model complex, non-linear relationships in data, capturing patterns that simpler models might miss. They also benefit from parallel processing capabilities which makes them efficient for large-scale data processing. Despite their complexity, neural networks can provide insights into the relationships between input features and target variables, aiding in the interpretation of learned patterns and relationships. When trained properly, they generalize well to new, unseen data, offering robust and reliable predictions.Additionally, neural networks are suitable for a wide range of applications, allowing them to tackle diverse problem domains. Lastly, they have a flexible architecture that allows for experimentation with different configurations, including the number of layers, neurons and activation functions. This flexibility enables the tailoring of models to specific tasks and data characteristics. Moreover, neural networks can automatically learn features from raw data, reducing the need for manual feature engineering. 7.4.2 Limitations Despite their strengths, neural networks have several limitations that can hinder their performance and applicability. One major limitation is their requirement for large datasets. Neural networks need vast amounts of labeled data to train effectively, which can be a significant barrier in domains where data is scarce. Additionally, they are computationally intensive, requiring powerful GPUs and large memory for training, which can be a constraint in some environments. The complexity and interpretability of neural networks are also significant challenges. As model architectures become more complex, they often turn into “black boxes,” making it difficult to understand how decisions are made. This decreased interpretability can be problematic in applications where understanding the decision-making process is crucial. Furthermore, neural networks are vulnerable to small perturbations to input data which can lead to significant errors in predictions. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
